{"cells":[{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nfrom decimal import Decimal\n\nclass Block(torch.nn.Module):\n\n    def __init__(self, num_channel):\n        super(Block, self).__init__()\n        self.pad1 = torch.nn.ZeroPad2d(1)\n        self.conv1 = torch.nn.Conv2d(num_channel, num_channel, kernel_size=3)\n        self.batch_norm1 = torch.nn.BatchNorm2d(num_channel)\n        self.relu1 = torch.nn.ReLU()\n        self.pad2 = torch.nn.ZeroPad2d(1)\n        self.conv2 = torch.nn.Conv2d(num_channel, num_channel, kernel_size=3)\n        self.batch_norm2 = torch.nn.BatchNorm2d(num_channel)\n        self.relu2 = torch.nn.ReLU()\n\n        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu:0')\n        self.to(self.device)\n\n    def forward(self, x):\n        out = self.pad1(x)\n        out = self.conv1(out)\n        out = self.batch_norm1(out)\n        out = self.relu1(out)\n        out = self.pad2(out)\n        out = self.conv2(out)\n        out = self.batch_norm2(out)\n        out = out + x\n        out = self.relu2(out)\n        return out\n    \n    \nclass PolicyNetwork(torch.nn.Module):\n\n    def __init__(self, alpha, num_res=3, num_channel=3):\n        super(PolicyNetwork, self).__init__()\n\n        #self.input_channels = num_channel\n        self.state_channel = 3\n        self.num_res = num_res\n        self.res_block = torch.nn.ModuleDict()\n        self.num_channel = num_channel\n        self.historical_loss = []\n\n        # network metrics\n        self.training_losses = []\n        self.test_losses = []\n        self.training_accuracies = []\n        self.test_accuracies = []\n        self.test_iteration = []\n\n        self.model_name = \"VN-R\" + str(self.num_res) + \"-C\" + str(self.num_channel)\n\n        self.define_network()\n        # define optimizer\n        self.optimizer = torch.optim.Adam(lr=alpha, params=self.parameters())\n        self.loss = torch.nn.BCELoss()\n        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu:0')\n        self.to(self.device)\n\n    def define_network(self):\n        #policy head\n        self.policy_conv = torch.nn.Conv2d(self.num_channel, 2, kernel_size=1)\n        self.policy_batch_norm = torch.nn.BatchNorm2d(2)\n        self.relu = torch.nn.ReLU()\n        self.policy_fc = torch.nn.Linear(2*9*9, 82)\n        self.softmax = torch.nn.Softmax(dim=1)\n        self.sigmoid = torch.nn.Sigmoid()\n\n        # network start\n        self.pad = torch.nn.ZeroPad2d(1)\n        self.conv = torch.nn.Conv2d(self.state_channel, self.num_channel, kernel_size=3)\n        self.batch_norm = torch.nn.BatchNorm2d(self.num_channel)\n        self.relu = torch.nn.ReLU()\n\n        for i in range(1, self.num_res+1):\n            self.res_block[\"r\"+str(i)] = Block(self.num_channel)\n\n    def forward(self, x):\n        out = torch.Tensor(x.float()).to(self.device)\n\n        out = self.pad(out)\n        out = self.conv(out)\n        out = self.batch_norm(out)\n        out = self.relu(out)\n\n        for i in range(1, self.num_res+1):\n            out = self.res_block[\"r\"+str(i)](out)\n\n        # policy head\n        out = self.policy_conv(out)\n        out = self.policy_batch_norm(out)\n        out = self.relu(out)\n        out = out.reshape(-1, 2*9*9)\n        out = self.policy_fc(out)\n        out = self.sigmoid(out)\n        return out.to(torch.device('cpu:0'))\n    \n    def optimize(self, x, y, x_t, y_t,\n     batch_size=16, iterations=10, alpha=0.1, test_interval=1000, save=False):\n        \n        x_t = x_t.float()\n        y_t = y_t.float()\n        \n        a = \"-A\" + ('%E' % Decimal(str(alpha)))[-1]\n\n        model_name = \"PN-R\" + str(self.num_res) + \"-C\" + str(self.num_channel)\n        self.model_name = model_name\n        model_path = \"models/policy_net/{}\".format(model_name)\n        log_path = \"logs/policy_net/{}/\".format(model_name)\n\n        num_batch = x.shape[0]//batch_size\n        remainder = x.shape[0]%batch_size\n            \n        print(\"Training Model:\", model_name)\n        \n        # Train netowork\n        for iter in tqdm(range(iterations)):\n            # save the model after each iteration\n            if save:\n                #torch.save(self.state_dict(), self.model_name+\"-P{}.pt\".format(iter))\n                pass\n\n            for i in range(num_batch):\n                prediction = self.forward(x[i*batch_size:(i+1)*batch_size])\n                loss = self.loss(prediction, y[i*batch_size:(i+1)*batch_size].float())\n                del(prediction)\n                self.historical_loss.append(loss.detach())\n                self.optimizer.zero_grad()\n                if iter == 0 and i == 0: loss.backward(retain_graph=True)\n                else: loss.backward()\n                self.optimizer.step()\n                torch.cuda.empty_cache()\n\n                if (iter*num_batch + i)%test_interval == 0 and save:\n                    self.test_model(x_t, y_t)\n                    self.test_iteration.append(iter*num_batch + i)\n\n              \n                del(loss)\n\n            torch.cuda.empty_cache()\n            if save:\n                self.save_metrics()\n        \n        #torch.save(self.state_dict(), self.model_name+\"-P{}.pt\".format(\"Final\"))\n                \n    def test_model(self, x_t, y_t):\n        \n        prediction = self.forward(x_t)\n        test_accuracy = self.get_test_accuracy(prediction, y_t)\n        test_loss = self.get_test_loss(prediction, y_t)\n\n        m = len(self.historical_loss)\n        l = torch.Tensor(self.historical_loss)\n        training_loss = torch.sum(l)/m\n        \n        del(prediction)\n        torch.cuda.empty_cache()\n        self.historical_loss = []\n\n        self.test_accuracies.append(test_accuracy.detach().type(torch.float16))\n        self.test_losses.append(test_loss.detach().type(torch.float16))\n        self.training_losses.append(training_loss.type(torch.float16))\n\n\n    def get_test_accuracy(self, prediction, y_t):\n\n        c = torch.zeros(y_t.shape[0], y_t.shape[1])\n        \n        c[prediction == prediction.max(dim=0)[0]] = 1\n        c[prediction != prediction.max(dim=0)[0]] = 0\n\n        correct_percent = torch.sum(c*y_t) / y_t.shape[0]\n\n        return correct_percent\n\n    def get_test_loss(self, prediction, y_t):\n        return self.loss(prediction, y_t)\n\n    def save_training_loss(self, path=\"\"):\n        file_name = path + self.model_name+\"-Train-Loss.csv\"\n        file = open(file_name, \"w\")\n        file.write(\"iteration,loss\\n\")\n        for iteration, loss in enumerate(self.training_losses):\n            file.write(\"{},{}\\n\".format(iteration, loss))\n        file.close()\n        \n    def save_test_loss(self, path=\"\"):\n        assert len(self.test_losses) == len(self.test_iteration)\n        file_name = path + self.model_name+\"-Test-Loss.csv\"\n        file = open(file_name, \"w\")\n        file.write(\"iteration,loss\\n\")\n        for i, loss in enumerate(self.test_losses):\n            file.write(\"{},{}\\n\".format(self.test_iteration[i], loss))\n        file.close()\n\n    def save_test_accuracy(self, path=\"\"):\n        assert len(self.test_accuracies) == len(self.test_iteration)\n        file_name = path + self.model_name+\"-Test-Accuracy.csv\"\n        file = open(file_name, \"w\")\n        file.write(\"iteration,accuracy\\n\")\n        for i, acc in enumerate(self.test_accuracies):\n            file.write(\"{},{}\\n\".format(self.test_iteration[i], acc))\n        file.close()\n\n    def save_metrics(self):\n        self.save_training_loss(self.model_name)\n        self.save_test_loss(self.model_name)\n        self.save_test_accuracy(self.model_name)\n        \n    def save(self):\n        torch.save(self.state_dict(), self.model_name+\".pt\")\n        \ndef generate_data(num_games=1000):\n    x = []\n    y = []\n    x_path = \"/kaggle/input/godataset/new_ogs_tensor_games/DataX\"\n    y_path = \"/kaggle/input/godataset/new_ogs_tensor_games/DataY\"\n    for i in range(num_games):\n        try:\n            x.append(torch.load(x_path+str(i)+\".pt\"))\n            y.append(torch.load(y_path+str(i)+\".pt\"))\n        except:pass\n    \n    x = torch.cat(x)\n    y = torch.cat(y)\n\n    ts = int(x.shape[0]*0.95)\n    x_t, y_t = x[ts:], y[ts:][:,0:82].reshape(y[ts:].shape[0], 82)\n    rand_perm = torch.randperm(x_t.shape[0])\n    x_t, y_t = x_t[rand_perm], y_t[rand_perm]\n    x_t = x_t[0:250]\n    y_t = y_t[0:250]\n    \n    rand_perm = torch.randperm(x[0:ts].shape[0])\n    x = x[0:ts][rand_perm]\n    y = y[0:ts][:,0:82].reshape(y[0:ts].shape[0], 82)[rand_perm]\n\n    print(\"Data Samples:\", x.shape[0])\n    \n    return x, y, x_t, y_t\n\ndef main():\n    import torch\n    \n    x, y, x_t, y_t = generate_data(num_games=2000)\n    \n    for res in [5, 8, 12, 15]:\n        for chan in [64, 128, 256]:\n            # clear cache and define network\n            torch.cuda.empty_cache()\n            policy_net = PolicyNetwork(alpha=0.000001, num_res=res, num_channel=chan)\n\n            # train model\n            policy_net.optimize(x, y, x_t, y_t, batch_size=64,\n                                       iterations=20, alpha=0.000001, test_interval=10, save=True)\n            #value_net.save()\n\n            # clear cache and remove old network\n            del(policy_net)\n            torch.cuda.empty_cache()           \n\nif __name__ == \"__main__\":\n    main()","metadata":{"collapsed":false,"_kg_hide-input":false},"execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}